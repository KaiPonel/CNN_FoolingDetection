{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user tensorflow\n",
    "#!pip install --user sklearn\n",
    "#!pip install --user lime\n",
    "#!pip install --user tf-explain\n",
    "#!pip install --user opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8-gTy5kP03mJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 15:53:02.550212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 15:53:03.966546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/scratch/ponel/python/lib:/usr/local/cuda-11.3/tensorRT-8.0/lib64:/usr/local/cuda-11.3/cudnn-8.2/lib64:/usr/local/cuda-11.3/nccl-2.9/lib64\n",
      "2023-05-25 15:53:03.966697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/scratch/ponel/python/lib:/usr/local/cuda-11.3/tensorRT-8.0/lib64:/usr/local/cuda-11.3/cudnn-8.2/lib64:/usr/local/cuda-11.3/nccl-2.9/lib64\n",
      "2023-05-25 15:53:03.966711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI9_t99r_fgt"
   },
   "source": [
    "## Random imports go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 25 15:53:08 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 22%   36C    P2    72W / 250W |  10111MiB / 11264MiB |     28%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 22%   28C    P8     1W / 250W |    335MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:DA:00.0 Off |                  N/A |\n",
      "| 22%   26C    P8    17W / 250W |    335MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:DB:00.0 Off |                  N/A |\n",
      "| 22%   26C    P8    21W / 250W |    335MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l1Vn3E9bBObk"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4LNoIwfjz2h",
    "outputId": "55afdd12-27f1-4eb8-f407-8796b7b6d199"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import tree\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cx4O-y76qZoG"
   },
   "outputs": [],
   "source": [
    "from tf_explain.core import GradCAM, IntegratedGradients, VanillaGradients, GradientsInputs, OcclusionSensitivity\n",
    "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
    "from tf_explain.callbacks.vanilla_gradients import VanillaGradientsCallback\n",
    "from tf_explain.callbacks.gradients_inputs import GradientsInputsCallback\n",
    "from tf_explain.callbacks.occlusion_sensitivity import OcclusionSensitivityCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKwQb9H_3y9P"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "h2BizadrMf8C"
   },
   "outputs": [],
   "source": [
    "img_dim_x = 28\n",
    "img_dim_y = 28\n",
    "img_dim_z = 1\n",
    "\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MNIST(dirpath='/data/project/FoolingDetection/mnist.npz'):\n",
    "    with np.load(dirpath) as data:\n",
    "        x_train, y_train = data['x_train'], data['y_train']\n",
    "        x_test, y_test = data['x_test'], data['y_test']\n",
    "\n",
    "    x_train = x_train/255\n",
    "    x_test = x_test/255\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5Fk7aRE31P-",
    "outputId": "d9298396-21ef-4984-919e-06028a2c0f84"
   },
   "outputs": [],
   "source": [
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\"Load a single batch of the CIFAR-10 dataset\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f, encoding='bytes')\n",
    "        X = datadict[b'data']\n",
    "        Y = datadict[b'labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def load_CIFAR10(dirpath=\"/data/project/FoolingDetection/cifar-10-batches-py\"):\n",
    "    \"\"\"Load all batches of the CIFAR-10 dataset from a directory\"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1, 5):\n",
    "        f = os.path.join(dirpath, 'data_batch_%d' % (b,))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(dirpath, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "v22yi60oqMNJ"
   },
   "outputs": [],
   "source": [
    "def to_rgb(x):\n",
    "    x_rgb = np.zeros((x.shape[0], img_dim_x, img_dim_y, img_dim_z))\n",
    "    for i in range(3):\n",
    "        x_rgb[..., i] = x[..., 0]\n",
    "    return x_rgb\n",
    "\n",
    "#x_train_rgb = to_rgb(x_train)\n",
    "#x_test_rgb = to_rgb(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_MNIST()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-DPPFOXnG-K"
   },
   "source": [
    "## Stop early!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "h57A7VuZBpvC"
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "  monitor=\"val_loss\",\n",
    "  patience=3,  \n",
    "  restore_best_weights=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9k_1BeOgnNFP"
   },
   "source": [
    "## Some Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8DooGnkXU-sG"
   },
   "outputs": [],
   "source": [
    "### Hyperparameters\n",
    "# Instantiate an optimizer, initializer, regularizer, loss_fn\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "regularizer = tf.keras.regularizers.L2(1e-4)\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CabMDZugnPTj"
   },
   "source": [
    "## I C an NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JwaxTu75SXxX"
   },
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "    GradCAMCallback(class_index=0, validation_data=(x_test, y_test)),\n",
    "    VanillaGradientsCallback(class_index=0, validation_data=(x_test, y_test)),\n",
    "    GradientsInputsCallback(class_index=0, validation_data=(x_test, y_test)),\n",
    "    # OcclusionSensitivityCallback(class_index=0, patch_size=4, validation_data=(x_test, y_test))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:1\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:1',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "# Define a distribution strategy that uses only GPUs 0 and 1\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "def get_model_raw():\n",
    "    with strategy.scope():\n",
    "        ### Hyperparameters\n",
    "        # Instantiate an optimizer, initializer, regularizer, loss_fn\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "        regularizer = tf.keras.regularizers.L2(1e-4)\n",
    "        loss_fn = tf.losses.SparseCategoricalCrossentropy()\n",
    "        metrics=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "        # Alternative model from kaggle:\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(layers.Conv2D(img_dim_x, (3,3), padding='same', activation='relu', input_shape=(img_dim_x,img_dim_y,img_dim_z)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Conv2D(img_dim_x, (3,3), padding='same', activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(10))\n",
    "        model.add(layers.Activation('softmax'))\n",
    "        \n",
    "        model.compile(loss=loss_fn, optimizer='adam', metrics=[metrics])\n",
    "        return model\n",
    "model = get_model_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mZUUEwqVGqb",
    "outputId": "d8f307b0-b44c-4673-8142-f1650677a46f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 15:49:20.930093: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 179.44MiB (rounded to 188160000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-05-25 15:49:20.930593: W tensorflow/tsl/framework/bfc_allocator.cc:492] ****________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1644446/1424706848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.fit(x_train, y_train, epochs=2, batch_size=128, validation_data=(x_test,y_test), callbacks=callbacks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/ponel/python/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ponel/python/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train, epochs=2, batch_size=128, validation_data=(x_test,y_test), callbacks=callbacks)\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_test,y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyu8fxJ8-2HZ"
   },
   "source": [
    "# Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlqb76LX-5a0"
   },
   "source": [
    "## Naive approach: Take two images (or heatmap) (with same dimensions) and calculate different similarity metrics for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BMNpUeUy_UBa"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2vy1ZOnx-40X"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(im1, im2):\n",
    "    im1 = im1.flatten()\n",
    "    im2 = im2.flatten()\n",
    "    return np.linalg.norm(im1 - im2)\n",
    "\n",
    "def manhattan_distance(im1, im2):\n",
    "    im1 = im1.flatten()\n",
    "    im2 = im2.flatten()\n",
    "    return distance.cityblock(im1, im2)\n",
    "  \n",
    "def minkowski_distance(im1, im2, p): # p=1 <-> Manhatten, p=2 Euclidian\n",
    "    im1 = im1.flatten()\n",
    "    im2 = im2.flatten()\n",
    "    return distance.minkowski(im1, im2, p)\n",
    "\n",
    "def chebyshev_distance(im1, im2):\n",
    "    im1 = im1.flatten()\n",
    "    im2 = im2.flatten()\n",
    "    return distance.chebyshev(im1, im2)\n",
    "\n",
    "def cosine_sim(im1, im2):\n",
    "    im1 = im1.flatten()\n",
    "    im2 = im2.flatten()\n",
    "    return cosine_similarity(im1.reshape(1, -1), im2.reshape(1, -1))\n",
    "\n",
    "def compute_ssim(im1, im2, multichannel=True):\n",
    "    return ssim(im1, im2, multichannel=multichannel)\n",
    "\n",
    "def run_all_distance_metrics(p1, p2):\n",
    "  minkowski_p = 3\n",
    "  return {\"euclidean:\": euclidean_distance(p1,p2),\n",
    "          \"manhatten:\": manhattan_distance(p1,p2),\n",
    "          \"minkowski-{}\".format(minkowski_p): minkowski_distance(p1, p2, minkowski_p),\n",
    "          \"chebyshev\": chebyshev_distance(p1,p2),\n",
    "          \"cosine sim\" : cosine_sim(p1,p2)\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_1rCtveUEHC"
   },
   "source": [
    "# Running various techniques on more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y33VuqOIUnXS"
   },
   "source": [
    "## Run the different explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a dict with key=class values=data\n",
    "def create_dict_classes_datapoints(x_test, y_test):\n",
    "    class_dict = {}\n",
    "    for i in range(len(x_test)):\n",
    "        key = y_test[i]\n",
    "        if key in class_dict:\n",
    "            class_dict[key].append(x_test[i])\n",
    "        else:\n",
    "            class_dict[key] = [x_test[i]]\n",
    "    return class_dict\n",
    "\n",
    "# Define sorted labels \n",
    "unique_sorted_labels = sorted(set(map(str, y_test)), key=lambda x: (not x.isdigit(), int(x) if x.isdigit() else x))\n",
    "images_by_class = create_dict_classes_datapoints(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qy8OtapPUasA",
    "outputId": "dfeef8bb-dbbb-4750-e58e-77676d52da80"
   },
   "outputs": [],
   "source": [
    "def run_explainers(x_in, y_in, model, NUM_IMAGES=300):\n",
    "\n",
    "    explainer_grad = GradCAM()\n",
    "    grids_gradcam = []\n",
    "    grids_gradcam_guided = []\n",
    "    explainer_ig = IntegratedGradients()\n",
    "    grids_ig = []\n",
    "    explainer_g_t_i = GradientsInputs()\n",
    "    grids_g_t_i = []\n",
    "    explainer_vgrads = VanillaGradients()\n",
    "    grids_vgrads = []\n",
    "    explainer_occlusion = OcclusionSensitivity()\n",
    "    grids_occlusion = []\n",
    "\n",
    "    # Iterate over the test_dataset for NUM_IMAGES. Run all the explanations using tf-explain and store the results in lists to be accessed later\n",
    "    for index, (x_example, y_example) in enumerate(zip(x_in, y_in)):\n",
    "      if index == NUM_IMAGES:\n",
    "        break\n",
    "      print(\"image: {}\".format(index))\n",
    "      x_example = ([x_example], None)\n",
    "      y_example_index = int(y_example)\n",
    "\n",
    "      grids_gradcam.append(explainer_grad.explain(x_example, model, class_index=y_example_index, use_guided_grads=False))\n",
    "      grids_gradcam_guided.append(explainer_grad.explain(x_example, model, class_index=y_example_index, use_guided_grads=True))\n",
    "      grids_ig.append(explainer_ig.explain(x_example, model, class_index=y_example_index))\n",
    "      grids_g_t_i.append(explainer_g_t_i.explain(x_example, model, class_index=y_example_index))\n",
    "      grids_vgrads.append(explainer_vgrads.explain(x_example, model, class_index=y_example_index))\n",
    "      grids_occlusion.append(explainer_occlusion.explain(x_example, model, class_index=y_example_index, patch_size=7))\n",
    "    \n",
    "    return [(grids_gradcam, \"gradcam\"), \n",
    "              (grids_gradcam_guided, \"gradcam_guided\"), \n",
    "              (grids_ig, \"ig\"), \n",
    "              (grids_g_t_i, \"g_t_i\"), \n",
    "              (grids_vgrads, \"vgrads\"), \n",
    "              (grids_occlusion, \"occlusion\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now store the grids on the local disk so we do not have to re-run this everytime\n",
    "\n",
    "\n",
    "# grid_list needs to match definiton in run_explainations()\n",
    "def save_grids_to_disk(grids_list, save_dir, dataset, model, attack=\"correct\", override=False):\n",
    "\n",
    "    # Define save directory\n",
    "    save_dir = os.path.join(save_dir, dataset, model, attack)\n",
    "    \n",
    "    if os.path.exists(save_dir) and not override:\n",
    "        raise Exception(\"The directory already exists and `override=False` was passed. Please make sure that you want to do this, this will delete any previous results.\")\n",
    "    \n",
    "    # Iterate over all grids and save them to corresponding subfolder\n",
    "    for grids, subfolder in grids_list:\n",
    "        subfolder_path = os.path.join(save_dir, subfolder)\n",
    "\n",
    "        # Create subdirectory if it does not exist\n",
    "        if not os.path.exists(subfolder_path):\n",
    "            os.makedirs(subfolder_path)\n",
    "\n",
    "        # Save each grid as an image\n",
    "        for i, grid in enumerate(grids):\n",
    "            plt.imshow(grid, cmap='hot', interpolation='nearest')\n",
    "            plt.savefig(os.path.join(subfolder_path, f\"{i}.png\"))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pDu9p8ntcgt4"
   },
   "outputs": [],
   "source": [
    "# New function to run the metrics which supports batches of images\n",
    "def run_all_distance_metrics_batch(P1, P2):\n",
    "    minkowski_p = 3\n",
    "    n = len(P1)\n",
    "    result = {\"euclidean\": 0,\n",
    "              \"manhattan\": 0,\n",
    "              \"minkowski-{}\".format(minkowski_p): 0,\n",
    "              \"chebyshev\": 0,\n",
    "              \"cosine sim\": 0}\n",
    "    for p1, p2 in zip(P1, P2):\n",
    "        result[\"euclidean\"] += euclidean_distance(p1,p2)\n",
    "        result[\"manhattan\"] += manhattan_distance(p1,p2)\n",
    "        result[\"minkowski-{}\".format(minkowski_p)] += minkowski_distance(p1, p2, minkowski_p)\n",
    "        result[\"chebyshev\"] += chebyshev_distance(p1,p2)\n",
    "        result[\"cosine sim\"] += cosine_sim(p1,p2)\n",
    "    for key in result:\n",
    "        result[key] /= n\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "-cS0tKNNQQKF",
    "outputId": "53cdf2f1-3d20-4126-b819-054cdcef8aae"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "GXjlhd7UIZ9L",
    "outputId": "b6bacfb4-3c45-4305-b87e-1a29038164b6"
   },
   "outputs": [],
   "source": [
    "# Printing an Occlusion sample to show which channels containw which information:\n",
    "# Longer Comment inc:\n",
    "# Sooo I looked into the documentation for this tf-explain module (https://github.com/sicara/tf-explain/blob/9d7d1e900ec3e3e4b5338fbc43dfb93539acecc2/tf_explain/core/occlusion_sensitivity.py#L64)\n",
    "# Turns out, for an to me unknown reason they resize their output from a n-d image to (always) an 3-d image. \n",
    "# This is why I'm just going to average the values of the 3 maps, because essentially, this is what they orginate from\n",
    "\n",
    "avg_grids_gradcam = [np.mean(image, axis=2) for image in grids_gradcam]\n",
    "# avg_grids_occlusion = [np.mean(image, axis=2) for image in grids_occlusion] # Average the channels of Occlusion to one channel\n",
    "# avg_grids_gradcam = [image[:,:,1] for image in grids_gradcam]\n",
    "avg_grids_occlusion = [image[:,:,2] for image in grids_occlusion]\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(grids_occlusion[0][:,:,2], cmap='Blues')\n",
    "print(grids_occlusion[0][:, 14, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB5MzvcYbwJJ"
   },
   "source": [
    "## Same images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-Ozb8mOb0ii"
   },
   "source": [
    "### IG vs. Vanilla Grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQJKixcgb6dM",
    "outputId": "82fe890f-7447-4615-d88f-e239cc32e8d2"
   },
   "outputs": [],
   "source": [
    "metrics_ig_vs_vgrads = run_all_distance_metrics_batch(grids_ig, grids_vgrads)\n",
    "print(metrics_ig_vs_vgrads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NzMqikbdvsU"
   },
   "source": [
    "### IG vs. Gradients*inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JNI_fQld4oU",
    "outputId": "8981bf0c-9f60-4842-a41d-3a0d98a55ac4"
   },
   "outputs": [],
   "source": [
    "metrics_ig_vs_gti = run_all_distance_metrics_batch(grids_ig, grids_g_t_i)\n",
    "print(metrics_ig_vs_gti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsqycplY8P7_"
   },
   "source": [
    "### IG vs. GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBgqfkPs8P7_",
    "outputId": "3b2b087d-c45b-48a3-a79c-29e8a7b14106"
   },
   "outputs": [],
   "source": [
    "metrics_ig_vs_gradcam = run_all_distance_metrics_batch(grids_ig, avg_grids_gradcam)\n",
    "print(metrics_ig_vs_gradcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7pVubC48fX8"
   },
   "source": [
    "### IG vs. Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGB5CPIA8fX9",
    "outputId": "04b627e5-905a-498e-dd8c-2d9e266b46b6"
   },
   "outputs": [],
   "source": [
    "metrics_ig_vs_occlusion = run_all_distance_metrics_batch(grids_ig, avg_grids_occlusion)\n",
    "print(metrics_ig_vs_occlusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEi54-gleCu7"
   },
   "source": [
    "### Vanilla Grads vs. Gradients*Inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YI6KU80-eGAH",
    "outputId": "934e5449-481b-4795-df1d-145a26490b9d"
   },
   "outputs": [],
   "source": [
    "metrics_vgrads_vs_gti = run_all_distance_metrics_batch(grids_vgrads, grids_g_t_i)\n",
    "print(metrics_vgrads_vs_gti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBE3huk2pv2D"
   },
   "source": [
    "### Vanilla Grads vs. GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Un43QuZp2Hho",
    "outputId": "30867882-c027-4138-d4b1-f38bd1207a30"
   },
   "outputs": [],
   "source": [
    "metrics_vgrads_vs_gradcam = run_all_distance_metrics_batch(grids_vgrads, avg_grids_gradcam)\n",
    "print(metrics_vgrads_vs_gradcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg9NcAbF9HCZ"
   },
   "source": [
    "### Vanilla Grads vs. Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKe6FwOu9HCi",
    "outputId": "00e9bac1-4ea5-4a5e-884a-3ff88fdc735a"
   },
   "outputs": [],
   "source": [
    "metrics_vgrads_vs_occlusion = run_all_distance_metrics_batch(grids_vgrads, avg_grids_occlusion)\n",
    "print(metrics_vgrads_vs_occlusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlsQbF9xHNVu"
   },
   "source": [
    "### Gradients*Inputs vs. GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qh5pkPFLfet",
    "outputId": "84a60a18-e2b6-4227-961b-d4d033fde500"
   },
   "outputs": [],
   "source": [
    "metrics_gi_vs_gradcam = run_all_distance_metrics_batch(grids_g_t_i, avg_grids_gradcam)\n",
    "print(metrics_gi_vs_gradcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ic2bnLD9sXv"
   },
   "source": [
    "### Gradients*Inputs vs. Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iR4QAOU-9sXw",
    "outputId": "46fa088b-44d4-4359-c05d-101f201e6289"
   },
   "outputs": [],
   "source": [
    "metrics_gi_vs_occlusion = run_all_distance_metrics_batch(grids_g_t_i, avg_grids_occlusion)\n",
    "print(metrics_gi_vs_occlusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FSiSOey99Kc"
   },
   "source": [
    "### GradCAM vs. Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4q6oZGGn99Kc",
    "outputId": "4f01f469-0249-4f74-aeec-eb48d1f6d161"
   },
   "outputs": [],
   "source": [
    "metrics_gradcam_vs_occlusion = run_all_distance_metrics_batch(avg_grids_gradcam, avg_grids_occlusion)\n",
    "print(metrics_gradcam_vs_occlusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLTFr5N1eRdK"
   },
   "source": [
    "## Different images \n",
    "Here we take the batches of images and set one batch of by a constant _shift_ s. This means that now no longer the same indexes of two gridlists correspond to the same image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4FCTZbRfPHm"
   },
   "outputs": [],
   "source": [
    "def rearrange_images(list_of_images, s):\n",
    "    n = len(grids_ig)\n",
    "    new_grids_ig = [None] * n\n",
    "    for i in range(n):\n",
    "        new_grids_ig[(i + s) % n] = grids_ig[i]\n",
    "    return new_grids_ig\n",
    "\n",
    "grids_ig_offset = rearrange_images(grids_ig, 1)\n",
    "grids_vgrads_offset = rearrange_images(grids_vgrads, 1)\n",
    "grids_g_t_i_offset = rearrange_images(grids_g_t_i, 1)\n",
    "avg_grids_gradcam_offset = rearrange_images(avg_grids_gradcam, 1) # Average the channels of GradCAM to one channel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuSFj60peiFD"
   },
   "source": [
    "### IG vs. Vanilla Grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGT_Cfo2ekqj",
    "outputId": "17caafbd-8863-4db3-e816-41cf0ee41535"
   },
   "outputs": [],
   "source": [
    "metrics_ig_vs_vgrads_diff = run_all_distance_metrics_batch(grids_ig_offset, grids_vgrads)\n",
    "print(metrics_ig_vs_vgrads_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfMKYIc_f5M0"
   },
   "source": [
    "### IG vs. Gradients*Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPj6zyOPgBa6",
    "outputId": "00c11e63-347c-42ba-a8ef-4816edc14e4b"
   },
   "outputs": [],
   "source": [
    "metrics_ig_vs_gti_diff = run_all_distance_metrics_batch(grids_ig_offset, grids_g_t_i)\n",
    "print(metrics_ig_vs_gti_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFYd_8Io-RO4"
   },
   "source": [
    "### IG vs. GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Av5rrGA2-RO_",
    "outputId": "563860bb-ce10-4904-d34c-310501cbd6b4"
   },
   "outputs": [],
   "source": [
    "metrics_ig_vs_gradcam_diff = run_all_distance_metrics_batch(grids_ig_offset, avg_grids_gradcam)\n",
    "print(metrics_ig_vs_gradcam_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCpEoym2-haR"
   },
   "source": [
    "### IG vs. Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zE5NglM-haS",
    "outputId": "b7d71173-95c6-4826-92c1-00e0d608f30d"
   },
   "outputs": [],
   "source": [
    "metrics_ig_vs_occlusion_diff = run_all_distance_metrics_batch(grids_ig_offset, avg_grids_occlusion)\n",
    "print(metrics_ig_vs_occlusion_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hcgpKYggYkz"
   },
   "source": [
    "### Vanilla Grads vs. Gradients*Inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgadUjN_gYB-",
    "outputId": "bdf7fdd0-a6b1-4d35-db27-f311a5b094d0"
   },
   "outputs": [],
   "source": [
    "metrics_vgrads_vs_gti_diff = run_all_distance_metrics_batch(grids_vgrads_offset, grids_g_t_i)\n",
    "print(metrics_vgrads_vs_gti_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gz8sxm5BGq5X"
   },
   "source": [
    "### Vanilla Grads vs. GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKUlde69Gt19",
    "outputId": "3a7476fe-85bb-484d-ad3e-7024f30730c5"
   },
   "outputs": [],
   "source": [
    "metrics_vgrads_vs_gradcam_diff = run_all_distance_metrics_batch(grids_vgrads_offset, avg_grids_gradcam)\n",
    "print(metrics_vgrads_vs_gradcam_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkE9yx4SL0jO"
   },
   "source": [
    "### Vanilla Grads vs. Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umLGhJO1L3Bb",
    "outputId": "efb049dd-0d53-4b54-a09a-ba7f668ba425"
   },
   "outputs": [],
   "source": [
    "metrics_vgrads_vs_occlusion_diff = run_all_distance_metrics_batch(grids_vgrads_offset, avg_grids_occlusion)\n",
    "print(metrics_vgrads_vs_occlusion_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEReezM7_MzN"
   },
   "source": [
    "### Gradients*Inputs vs. GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phE00J67_MzO",
    "outputId": "3eb59bfc-3fb4-44e0-c405-6ec14cb044f1"
   },
   "outputs": [],
   "source": [
    "metrics_gi_vs_gradcam_diff = run_all_distance_metrics_batch(grids_g_t_i_offset, avg_grids_gradcam)\n",
    "print(metrics_gi_vs_gradcam_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jJCrvK__mOr"
   },
   "source": [
    "### Gradients*Inputs vs. Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpsbIV-3_mOs",
    "outputId": "6c6a2651-d088-4f30-d6b0-015bd00f101d"
   },
   "outputs": [],
   "source": [
    "metrics_gi_vs_occlusion_diff = run_all_distance_metrics_batch(grids_g_t_i_offset, avg_grids_occlusion)\n",
    "print(metrics_gi_vs_occlusion_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlFF081t_soH"
   },
   "source": [
    "### GradCAM vs. Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-v4el8sc_soI",
    "outputId": "aee9f949-eda3-4516-dc95-df1c74fd76c6"
   },
   "outputs": [],
   "source": [
    "metrics_gradcam_vs_occlusion_diff = run_all_distance_metrics_batch(avg_grids_gradcam_offset, avg_grids_occlusion)\n",
    "print(metrics_gradcam_vs_occlusion_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmJKPjcKAUyo"
   },
   "source": [
    "## Comparison: Same and Different images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGAMVljZAjVA",
    "outputId": "5c11e46f-535a-43ec-dcd6-373d563e769f"
   },
   "outputs": [],
   "source": [
    "print(\"IG vs. Vanilla Gradients:\")\n",
    "print(\"same: {}\".format(metrics_ig_vs_vgrads))\n",
    "print(\"diff: {}\".format(metrics_ig_vs_vgrads_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"IG vs. G*I:\")\n",
    "print(\"same: {}\".format(metrics_ig_vs_gti))\n",
    "print(\"diff: {}\".format(metrics_ig_vs_gti_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"IG vs. GradCAM:\")\n",
    "print(\"same: {}\".format(metrics_ig_vs_gradcam))\n",
    "print(\"diff: {}\".format(metrics_ig_vs_gradcam_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"IG vs. Occlusion:\")\n",
    "print(\"same: {}\".format(metrics_ig_vs_occlusion))\n",
    "print(\"diff: {}\".format(metrics_ig_vs_occlusion_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"vgrads vs. G*I:\")\n",
    "print(\"same: {}\".format(metrics_vgrads_vs_gti))\n",
    "print(\"diff: {}\".format(metrics_vgrads_vs_gti_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"vgrads vs. GradCAM:\")\n",
    "print(\"same: {}\".format(metrics_vgrads_vs_gradcam))\n",
    "print(\"diff: {}\".format(metrics_vgrads_vs_gradcam_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"vgrads vs. Occlusion:\")\n",
    "print(\"same: {}\".format(metrics_vgrads_vs_occlusion))\n",
    "print(\"diff: {}\".format(metrics_vgrads_vs_occlusion_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"G*I vs. GradCAM:\")\n",
    "print(\"same: {}\".format(metrics_gi_vs_gradcam))\n",
    "print(\"diff: {}\".format(metrics_gi_vs_gradcam_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"G*I vs. Occlusion:\")\n",
    "print(\"same: {}\".format(metrics_gi_vs_occlusion))\n",
    "print(\"diff: {}\".format(metrics_gi_vs_occlusion_diff))\n",
    "print(\"------------------------------------------\")\n",
    "print(\"GradCAM vs. Occlusion:\")\n",
    "print(\"same: {}\".format(metrics_gradcam_vs_occlusion))\n",
    "print(\"diff: {}\".format(metrics_gradcam_vs_occlusion_diff))\n",
    "print(\"------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random label test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_random_labels(y):\n",
    "    unique_values = list(set(y))\n",
    "    return [random.choice(unique_values) for _ in y]\n",
    "\n",
    "y_train_random = np.asarray(generate_random_labels(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:57:33.178577: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-05-25 16:57:38.600720: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout_8/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42/469 [=>............................] - ETA: 8s - loss: 3.4519 - sparse_categorical_accuracy: 0.0913"
     ]
    }
   ],
   "source": [
    "model_random_labels = get_model_raw()\n",
    "model_random_labels.fit(x_train, y_train_random, epochs=100, batch_size=128, validation_data=(x_test,y_test),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = run_explainers(x_test, y_test, model_random_labels, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_grids_to_disk(grids_list=explanations, save_dir=\"/project/FoolingDetection/grids\", dataset=\"mnist\", model=\"cnn\", attack=\"random_labels\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameter Randomization Test (Indepdent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be run for longer.\n",
    "\n",
    "def run_random_model_param_test_indep():\n",
    "    # 1. Do training \n",
    "    model_random_params = get_model_raw()\n",
    "    model_random_params.fit(x_train, y_train, epochs=3, batch_size=128, validation_data=(x_test,y_test),callbacks=[early_stopping])\n",
    "    \n",
    "    # Loop over layers: Randomize one layer at a time\n",
    "    original_weights = [layer.get_weights() for layer in model_random_params.layers]\n",
    "    for i in range(len(model_random_params.layers)-1, -1, -1):\n",
    "        # Reset the weights to their original values\n",
    "        for j, layer in enumerate(model_random_params.layers):\n",
    "            layer.set_weights(original_weights[j])\n",
    "\n",
    "        # Randomize the weights of the current layer if it has weights\n",
    "        layer = model_random_params.layers[i]\n",
    "        weights = layer.get_weights()\n",
    "        if weights:  # Check if the layer has weights\n",
    "            randomized_weights = [np.random.rand(*w.shape) for w in weights]\n",
    "            layer.set_weights(randomized_weights)\n",
    "            layer_name = layer.name\n",
    "            grids = run_explainers(x_test, y_test, model_random_params, 300)\n",
    "            save_grids_to_disk(grids_list=grids, save_dir=\"/project/FoolingDetection/grids\", dataset=\"mnist\", model=\"cnn\", attack=\"RandParams/Independent/{}_{}\".format(i, layer_name), override=False)\n",
    "        # Now you can generate your saliency maps and observe the impact of the weight randomization\n",
    "        # ...\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 15:57:36.458793: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/dropout_12/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 20s 26ms/step - loss: 0.3900 - sparse_categorical_accuracy: 0.8796 - val_loss: 2.6590 - val_sparse_categorical_accuracy: 0.3857\n",
      "Epoch 2/3\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.0942 - sparse_categorical_accuracy: 0.9712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 15:58:01.570811: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0942 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.0285 - val_sparse_categorical_accuracy: 0.9901\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9801 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9916\n",
      "image: 0\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "image: 1\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 15:58:32.574946: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 13\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 1\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 91ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 15:59:02.740919: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 10\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "image: 1\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 15:59:33.605032: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 7\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 1\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:00:04.209795: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 4\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:00:35.128870: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:01:10.431881: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:01:42.760572: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 1s 649ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:02:19.005437: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:02:54.854902: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:03:27.556093: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:04:04.456229: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:04:38.213147: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:05:16.323753: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:05:49.634859: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 0\n",
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:06:22.754835: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "image: 2\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 3\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 4\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "image: 5\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "image: 6\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 7\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 8\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 9\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "image: 10\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 11\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "image: 12\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "image: 13\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 14\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 15\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "image: 16\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "image: 17\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "image: 18\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "image: 19\n",
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    }
   ],
   "source": [
    "run_random_model_param_test_indep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameter Randomization Test (Cascading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be run for longer.\n",
    "\n",
    "def run_random_model_param_test_cascading():\n",
    "    # 1. Do training \n",
    "    model_random_params = get_model_raw()\n",
    "    model_random_params.fit(x_train, y_train, epochs=3, batch_size=128, validation_data=(x_test,y_test),callbacks=[early_stopping])\n",
    "    \n",
    "    # Loop over layers: Randomize one layer at a time\n",
    "    original_weights = [layer.get_weights() for layer in model_random_params.layers]\n",
    "    for i in range(len(model_random_params.layers)-1, -1, -1):\n",
    "        # Randomize the weights of the current layer if it has weights\n",
    "        layer = model_random_params.layers[i]\n",
    "        weights = layer.get_weights()\n",
    "        if weights:  # Check if the layer has weights\n",
    "            randomized_weights = [np.random.rand(*w.shape) for w in weights]\n",
    "            layer.set_weights(randomized_weights)\n",
    "            layer_name = layer.name\n",
    "            grids = run_explainers(x_test, y_test, model_random_params, 300)\n",
    "            save_grids_to_disk(grids_list=grids, save_dir=\"/project/FoolingDetection/grids\", dataset=\"mnist\", model=\"cnn\", attack=\"RandParams/Cascading/{}_{}\".format(i, layer_name), override=False)\n",
    "        # Now you can generate your saliency maps and observe the impact of the weight randomization\n",
    "        # ...\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_random_model_param_test_cascading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-O6o_fjdpbDL"
   },
   "source": [
    "# extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1l-SPuH2BwuY"
   },
   "outputs": [],
   "source": [
    "### Indepent Layer Randomization:\n",
    "\n",
    "# Save the original weights\n",
    "original_weights = [layer.get_weights() for layer in model.layers]\n",
    "\n",
    "for i in range(len(model.layers)-1, -1, -1):\n",
    "    # Reset the weights to their original values\n",
    "    for j, layer in enumerate(model.layers):\n",
    "        layer.set_weights(original_weights[j])\n",
    "    \n",
    "    # Randomize the weights of the current layer if it has weights\n",
    "    layer = model.layers[i]\n",
    "    weights = layer.get_weights()\n",
    "    if weights:  # Check if the layer has weights\n",
    "        randomized_weights = [np.random.rand(*w.shape) for w in weights]\n",
    "        layer.set_weights(randomized_weights)\n",
    "    \n",
    "    # Now you can generate your saliency maps and observe the impact of the weight randomization\n",
    "    # ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIbW5Ce7C6uF"
   },
   "outputs": [],
   "source": [
    "### Cascading Layer Randomization\n",
    "original_weights = [layer.get_weights() for layer in model.layers]\n",
    "\n",
    "for i in range(len(model.layers)-1, -1, -1):\n",
    "    # Randomize the weights of the current layer if it has weights\n",
    "    layer = model.layers[i]\n",
    "    weights = layer.get_weights()\n",
    "    if weights:  # Check if the layer has weights\n",
    "        randomized_weights = [np.random.rand(*w.shape) for w in weights]\n",
    "        layer.set_weights(randomized_weights)\n",
    "        # Update the original_weights list with the new randomized weights\n",
    "        original_weights[i] = randomized_weights\n",
    "    \n",
    "    # Now you can generate your saliency maps and observe the impact of the weight randomization\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQ2ztANUDL-9"
   },
   "outputs": [],
   "source": [
    "def generate_random_labels(y_test):\n",
    "    unique_values = list(set(y_test))\n",
    "    return [random.choice(unique_values) for _ in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Dictionaries to hold our images\n",
    "correct = {}\n",
    "layer_random_indep = {}\n",
    "layer_random_cascading = {}\n",
    "labels_random = {}\n",
    "\n",
    "# Directories\n",
    "dir_correct = os.path.join(save_dir, 'correct')\n",
    "dir_layer_random_indep = os.path.join(save_dir, 'layer_random_indep')\n",
    "dir_layer_random_cascading = os.path.join(save_dir, 'layer_random_cascading')\n",
    "dir_labels_random = os.path.join(save_dir, 'labels_random')\n",
    "\n",
    "# Function to load images from a directory into a dictionary\n",
    "def load_images(dir_path, img_dict):\n",
    "    for sub_dir in os.listdir(dir_path):\n",
    "        sub_dir_path = os.path.join(dir_path, sub_dir)\n",
    "        if os.path.isdir(sub_dir_path):\n",
    "            img_dict[sub_dir] = []\n",
    "            for file in os.listdir(sub_dir_path):\n",
    "                if file.endswith('.png'): # change this to the format of your images\n",
    "                    file_path = os.path.join(sub_dir_path, file)\n",
    "                    image = Image.open(file_path)\n",
    "                    img_dict[sub_dir].append(image)\n",
    "\n",
    "# Loading images into dictionaries\n",
    "load_images(dir_correct, correct)\n",
    "load_images(dir_layer_random_indep, layer_random_indep)\n",
    "load_images(dir_layer_random_cascading, layer_random_cascading)\n",
    "load_images(dir_labels_random, labels_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all dictionaries share the same keys\n",
    "assert set(correct.keys()) == set(layer_random_indep.keys()) == set(layer_random_cascading.keys()) == set(labels_random.keys())\n",
    "\n",
    "results = {\n",
    "    \"correct_layer_random_indep\": {},\n",
    "    \"correct_layer_random_cascading\": {},\n",
    "    \"correct_labels_random\": {}\n",
    "}\n",
    "\n",
    "for key in correct.keys():\n",
    "    result_indep = run_all_distance_metrics_batch(correct[key], layer_random_indep[key])\n",
    "    result_cascading = run_all_distance_metrics_batch(correct[key], layer_random_cascading[key])\n",
    "    result_labels = run_all_distance_metrics_batch(correct[key], labels_random[key])\n",
    "    \n",
    "    results[\"correct_layer_random_indep\"][key] = result_indep\n",
    "    results[\"correct_layer_random_cascading\"][key] = result_cascading\n",
    "    results[\"correct_labels_random\"][key] = result_labels\n",
    "\n",
    "# Now results is a dictionary where each value is a dictionary of the results of your function\n",
    "# for each pair of arrays in the corresponding dictionaries.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GsDItUSeIoEy",
    "-O6o_fjdpbDL"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
